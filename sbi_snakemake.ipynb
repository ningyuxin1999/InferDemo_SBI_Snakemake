{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53a86951-1369-4bb1-a102-fd356d27c1f4",
   "metadata": {},
   "source": [
    "# Simulation-Based Inference (SBI) in population genetics\n",
    "\n",
    "Welcome to this workshop on applying neural posterior estimation (NPE) in population genetics! In this notebook, we will explore together how to use our Snakemake pipeline for simulation-based inference in population genetics. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf2af66-f5e0-4646-a0e0-37fbbe9052f6",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "We'll walk you through:\n",
    "1. A brief overview of the SBI toolbox and NPE.\n",
    "2. Setting up the required environments? (probably should do this in advance)\n",
    "3. Reading in and exploring pre-simulated data.\n",
    "4. Training a posterior using the SBI toolbox.\n",
    "5. Evaluation of the posterior distribution (based on insufficient dataset).\n",
    "6. Loading a pre-trained posterior with evaluation.\n",
    "7. Visualisations\n",
    "\n",
    "   ...more ideas?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ad01a9-fad3-4b53-87d8-d3dc5f47af4e",
   "metadata": {},
   "source": [
    "### 1.1. A Brief Overview\n",
    "\n",
    "Neural posterior estimation (NPE) is provided within [sbi toolbox](https://github.com/sbi-dev/sbi) where we can learn the posterior distribution of parameters given observations using flexible neural networks. \n",
    "- It allows us to infer complex, high-dimensional parameters without relying on approximate likelihoods.\n",
    "- The approach is especially useful for scenarios where the likelihood function is expensive or intractable, but data simulation is feasible.\n",
    "  \n",
    "You can visit [sbi documentation](https://sbi-dev.github.io/sbi/latest/) for more information.\n",
    "\n",
    "Based on sbi, our [Snakemake](https://snakemake.readthedocs.io/en/stable/) pipeline provides a framework for simulation-based inference in population genetics using [msprime](https://tskit.dev/msprime/docs/stable/quickstart.html). It automates data simulation (e.g., tree sequences), training of neural posterior estimators (NPEs), and plotting/visualization of inferred parameters. \n",
    "\n",
    "Three different workflows are provided: an amortized msprime workflow, an amortized dadi workflow, and a sequential msprime workflow. Configuration files control the number of simulations, model details, and training settings, making the workflow flexible for various population genetic scenarios.\n",
    "For more information on this pipeline, please visit our [GitHub repository](https://github.com/your-org/your-sbi-snakemake-pipeline).\n",
    "\n",
    "- [ ] How should we present the pipeline -- DAG?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c8e27b-a08a-49ce-9f61-3ae41765fbd4",
   "metadata": {},
   "source": [
    "### 1.2. Prerequisites\n",
    "\n",
    "Before we begin, ensure the following:\n",
    "1. **Operating System**: Linux/macOS/Windows (with WSL2 or an equivalent environment).\n",
    "2. **Hardware**: (do we want to keep everything on CPU?)\n",
    "    - CPU with at least X cores (recommended).\n",
    "    - GPU (optional but recommended) for faster training with PyTorch.\n",
    "3. **Software**:\n",
    "    - Python 3.9+ [sbi0.22.0](https://github.com/sbi-dev/sbi/releases/tag/v0.22.0).\n",
    "    - [conda](https://docs.conda.io/en/latest/) (or `venv`) for environment management.\n",
    "    - Required Python libraries for this tutorial ([requirements](https://github.com/kr-colab/popgensbi_snakemake/blob/main/requirements.yaml)).\n",
    "\n",
    "#### Environment Setup\n",
    "\n",
    "To run this notebook, please follow these steps:\n",
    "1. Install [conda](https://docs.conda.io/en/latest/miniconda.html) if you haven’t already.\n",
    "2. Clone the repository: `git clone https://github.com/kr-colab/popgensbi_snakemake.git`\n",
    "3. Create the environment: `conda env create -f requirements.yaml`\n",
    "4. Activate the environment: `conda activate popgensbi_env`\n",
    "5. Launch Jupyter notebook: `jupyter notebook`.\n",
    "6. In the Notebook, select the \"popgensbi\" kernel if prompted.\n",
    "\n",
    "### 1.3. Environment Test\n",
    "\n",
    "- [ ] Here should be a short test block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37cdf995-2adb-409f-bc01-d12b03421f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: The following packages are missing: ['dadi']\n",
      "Please install or switch to the conda environment that has them.\n"
     ]
    }
   ],
   "source": [
    "# Are you ready to go?\n",
    "\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "# List of critical packages we expect\n",
    "required_packages = [\"snakemake\", \"msprime\", \"dadi\", \"sbi\", \"torch\"]\n",
    "missing_packages = []\n",
    "\n",
    "for pkg in required_packages:\n",
    "    try:\n",
    "        __import__(pkg)\n",
    "    except ImportError:\n",
    "        missing_packages.append(pkg)\n",
    "\n",
    "if missing_packages:\n",
    "    print(\"WARNING: The following packages are missing:\", missing_packages)\n",
    "    print(\"Please install or switch to the conda environment that has them.\")\n",
    "else:\n",
    "    print(\"All required packages found. Environment looks good!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9c9d36-4afe-4916-8a29-696ff028ea57",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Explore demographic inference: Simulated data and NPE\n",
    "\n",
    "Here we’ll load some pre-generated data in TSV format and explore it briefly. In this section, let's infer historical effective population sizes using summary statistics. Train your posterior quickly and play with it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09b6222a-5725-42e2-8dc8-d512b9ba4622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# path_population_sizes = '... .tsv'\n",
    "# path_summary_statistics = '.tsv'\n",
    "\n",
    "# # Read in the data\n",
    "# df_pop = pd.read_csv(path_population_sizes, sep='\\t')\n",
    "# df_sum = pd.read_csv(path_summary_statistics, sep='\\t')\n",
    "\n",
    "# print(f\"Shape of Ne: {df_pop.shape}\")\n",
    "# print(f\"Shape of summary statistics: {df_sum.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bf9051-f3b1-4c36-a7fa-9b49a9ba074a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_pop.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ddaa5a-8fc2-45a5-9175-fc59eedb956c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sum.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655d3669-bd3f-42cf-854b-30080a7c62b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sbi.inference import SNPE, prepare_for_sbi\n",
    "# import torch\n",
    "\n",
    "# # Convert to torch tensors\n",
    "# theta = torch.tensor(df[...].values, dtype=torch.float32)\n",
    "# x = torch.tensor(df[...].values, dtype=torch.float32)\n",
    "\n",
    "# inference = SNPE(prior=None)  # Usually, you'd define a prior or pass a prior object.\n",
    "\n",
    "# # Train the posterior (this can take a while, especially on CPU)\n",
    "# density_estimator = inference.append_simulations(theta, x).train()\n",
    "# posterior = inference.build_posterior(density_estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894736d9-fc3b-4abb-9776-70e5876b7cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_mse(true_params, inferred_params):\n",
    "#     return ((true_params - inferred_params)**2).mean().item()\n",
    "\n",
    "# observed_x = ... #testing set\n",
    "\n",
    "# # Sample from the posterior\n",
    "# with torch.no_grad():\n",
    "#     inferred_samples = posterior.sample((1000,), x=observed_x)  # get 1000 samples\n",
    "# inferred_mean = inferred_samples.mean(dim=0)\n",
    "\n",
    "# mse_value = compute_mse(true_params, inferred_mean)\n",
    "# print(f\"MSE for test index {test_index} = {mse_value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c4ef58-729f-47cc-b0ea-31484e5a2139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# posterior_path = 'pretrained_posterior.pkl'\n",
    "\n",
    "# with open(posterior_path, 'rb') as f:\n",
    "#     pretrained_posterior = pickle.load(f)\n",
    "\n",
    "# # Now we can do inference with the loaded posterior\n",
    "# test_index = 1\n",
    "# observed_x = x[test_index].unsqueeze(0)\n",
    "# true_params = theta[test_index]\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     inferred_samples = pretrained_posterior.sample((1000,), x=observed_x)\n",
    "# inferred_mean = inferred_samples.mean(dim=0)\n",
    "\n",
    "# mse_value = compute_mse(true_params, inferred_mean)\n",
    "# print(f\"Using the pre-trained posterior, MSE = {mse_value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32790fe7-38a7-400e-8b4b-ea96115ab648",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Extended scenarios\n",
    "\n",
    "- [ ] We can let people run the snakemake pipeline from this step, then use this notebook to work with the posterior.\n",
    "- [ ] Or, we can simply try out all the steps here in the notebook, just to get people familiar with the general workflow.\n",
    "- [ ] There will be a pre-trained posterior with testing data provided anyway, in case some accidence happen\n",
    "\n",
    "### 3.1 Customize the prior for your interest.\n",
    "\n",
    "- [ ] make the prior more flexible\n",
    "- [ ] define a simulator\n",
    "\n",
    "### 3.2 Compute summary statistics\n",
    "### 3.3 Customize neural network architecture/ work with embedding NN\n",
    "### 3.4 NPE training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f5b9de-01db-4701-b01b-983fae217425",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc067ecd-9a14-4a29-a215-4260e0346bd5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e82956f-793b-4842-b90d-cadaee6891b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3e041cdb-e933-4910-a552-d5e21fb06faa",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e5a39f-2071-4a37-bc43-1e66c7c918fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "581d4c73-be8f-43e0-b022-113854a4685f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4097df9e-2554-450b-8ae6-1552a2f270e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "00325d77-b858-40b5-8629-caf2e77f33a8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "So far we have walked through the complete workflow including data simulation and NPE training. \n",
    "There are different ways to visualize the posterior distribution using sbi integrated, or self-defined functions.\n",
    "...\n",
    "\n",
    "## 4. Evaluation and visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f19f6e-ac7e-4ceb-a678-f46ff0eeade0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "532db1f4-6c29-442c-8a26-0c1b90eeeaf4",
   "metadata": {},
   "source": [
    "Thank you for following along! We hope this tutorial helps you get started with the SBI Snakemake pipeline for population genetics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648df530-9de2-4119-ba30-d57b444c82b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sbi_env",
   "language": "python",
   "name": "sbi_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
